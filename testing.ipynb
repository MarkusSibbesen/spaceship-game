{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb611685f20e4c5280ba17d8947f74ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/722 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22d1f521aad4f93bd60d1a41f568539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afb847946514ec3b70d5edb998269e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66684a3a474b416494cf7443bfd87380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5218163c104480aa3476d0c9b8ceb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da7760b55714fe9b4a8c8d6a82dec5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/968 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad45669aa444b47b36a7f94869e4bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/291M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"roneneldan/TinyStories-33M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing steering vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little girl named Lucy. She was three years old and loved to explore. One day, Lucy was walking in the park when she saw a big, red balloon. She was so excited and ran over to it.\n",
      "\n",
      "\"Can I have it?\" she asked.\n",
      "\n",
      "\"No,\" said her mom. \"It's too big for you. You can't have it.\"\n",
      "\n",
      "Lucy was sad, but then she saw a small, red balloon\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once upon a time there was\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate completion\n",
    "output = model.generate(input_ids, max_length = 100, num_beams=1)\n",
    "\n",
    "# Decode the completion\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"roneneldan/TinyStories-33M\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPTNeoForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0,\n",
       "  \"attention_layers\": [\n",
       "    \"global\",\n",
       "    \"local\",\n",
       "    \"global\",\n",
       "    \"local\"\n",
       "  ],\n",
       "  \"attention_types\": [\n",
       "    [\n",
       "      [\n",
       "        \"global\",\n",
       "        \"local\"\n",
       "      ],\n",
       "      2\n",
       "    ]\n",
       "  ],\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"classifier_dropout\": 0.1,\n",
       "  \"embed_dropout\": 0,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": null,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"gpt_neo\",\n",
       "  \"num_heads\": 16,\n",
       "  \"num_layers\": 4,\n",
       "  \"resid_dropout\": 0,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257,\n",
       "  \"window_size\": 256\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vector = torch.rand(768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3280e-02, 6.1484e-01, 8.8170e-01, 2.3139e-01, 2.6736e-01, 9.3749e-01,\n",
       "        7.5023e-01, 5.8770e-01, 9.2062e-01, 2.1814e-02, 6.0033e-01, 8.7807e-01,\n",
       "        1.8568e-01, 7.5155e-01, 7.6272e-01, 2.1455e-02, 5.9136e-01, 2.8185e-01,\n",
       "        2.7721e-01, 4.4731e-01, 8.3279e-01, 5.3535e-01, 1.9647e-03, 3.8950e-01,\n",
       "        4.2321e-02, 7.7131e-01, 3.9817e-01, 4.3630e-01, 2.0418e-01, 6.7655e-01,\n",
       "        8.4338e-01, 1.9509e-01, 2.0098e-01, 1.1976e-01, 4.3911e-01, 9.0989e-01,\n",
       "        6.7099e-01, 8.9031e-01, 6.1250e-01, 7.1161e-01, 3.2539e-01, 6.1358e-02,\n",
       "        2.7537e-01, 2.8207e-01, 7.5822e-01, 9.9123e-01, 3.0670e-01, 3.5389e-01,\n",
       "        7.6642e-01, 8.6256e-01, 6.0758e-01, 3.2591e-02, 8.5203e-01, 3.5220e-01,\n",
       "        7.8824e-01, 2.0178e-01, 8.9091e-01, 3.7500e-01, 4.5110e-01, 8.9521e-01,\n",
       "        5.0265e-01, 9.2214e-01, 1.2056e-01, 4.7268e-01, 1.3482e-01, 1.6004e-01,\n",
       "        4.8950e-01, 2.4893e-01, 3.1386e-01, 4.4183e-01, 6.0493e-01, 8.5598e-01,\n",
       "        4.1757e-01, 1.9616e-02, 7.7358e-01, 8.8470e-01, 6.8978e-02, 8.8980e-01,\n",
       "        7.8170e-01, 7.4104e-01, 1.7484e-01, 6.7605e-01, 8.2376e-01, 3.8122e-01,\n",
       "        9.9421e-01, 4.5762e-02, 2.7489e-01, 4.0670e-02, 6.0349e-01, 3.4352e-01,\n",
       "        4.8719e-01, 3.3235e-01, 8.1521e-01, 7.9255e-01, 1.1570e-01, 3.9449e-01,\n",
       "        2.0333e-01, 8.1212e-01, 6.3968e-01, 2.2396e-01, 3.1580e-02, 8.9382e-01,\n",
       "        8.3989e-01, 9.9765e-01, 3.1890e-01, 9.8008e-01, 9.0200e-01, 5.4904e-01,\n",
       "        3.0752e-01, 3.6683e-01, 3.7860e-01, 2.3039e-02, 3.8542e-01, 6.6369e-01,\n",
       "        8.0130e-01, 6.4412e-01, 9.9654e-01, 9.4232e-01, 2.3450e-01, 4.3919e-01,\n",
       "        9.7370e-01, 6.7973e-01, 8.5082e-01, 5.1392e-01, 1.6517e-01, 1.8083e-02,\n",
       "        5.9011e-01, 8.1801e-01, 2.7614e-01, 5.1038e-01, 6.4271e-01, 9.9056e-01,\n",
       "        3.1438e-01, 4.9122e-01, 1.3190e-01, 1.3995e-01, 8.8328e-01, 8.2486e-01,\n",
       "        6.3323e-01, 7.3382e-01, 3.3553e-01, 8.2978e-01, 4.9968e-01, 4.4479e-01,\n",
       "        8.6464e-01, 7.1784e-01, 2.4260e-01, 7.1539e-01, 3.8776e-02, 3.1687e-02,\n",
       "        9.4159e-01, 1.0059e-01, 7.2529e-01, 8.8305e-01, 2.7476e-01, 4.6416e-01,\n",
       "        9.1019e-01, 4.0770e-01, 7.3197e-01, 1.1646e-01, 9.0858e-01, 6.2828e-01,\n",
       "        1.1263e-01, 1.9722e-01, 1.7090e-01, 6.0681e-01, 5.5060e-01, 1.0300e-01,\n",
       "        8.5134e-01, 3.1515e-01, 6.4821e-02, 2.4904e-01, 2.3916e-01, 7.0390e-01,\n",
       "        7.6120e-02, 8.0889e-01, 6.1189e-01, 8.5404e-01, 4.7382e-01, 4.0563e-01,\n",
       "        6.4121e-01, 5.0821e-01, 2.0108e-01, 4.1234e-01, 4.4921e-02, 8.1357e-01,\n",
       "        1.8137e-01, 3.5434e-01, 2.8997e-01, 3.1381e-01, 8.3624e-01, 9.5361e-01,\n",
       "        2.9490e-01, 2.1087e-01, 2.4953e-01, 2.1462e-01, 1.1263e-01, 5.1965e-01,\n",
       "        2.8853e-01, 7.7732e-01, 1.8902e-01, 5.1918e-02, 8.1658e-01, 3.8340e-01,\n",
       "        3.8031e-01, 1.2875e-01, 2.6395e-01, 9.1654e-01, 8.0613e-01, 6.3427e-01,\n",
       "        1.7561e-01, 7.1850e-01, 8.9989e-02, 2.1446e-01, 9.5106e-03, 7.1002e-01,\n",
       "        9.8700e-02, 7.9160e-01, 9.7755e-01, 3.2503e-01, 5.6858e-01, 2.8772e-01,\n",
       "        9.4365e-01, 4.8734e-01, 8.6060e-02, 9.7199e-01, 9.8250e-01, 5.9712e-01,\n",
       "        4.5605e-01, 1.7523e-01, 6.9960e-01, 2.0132e-01, 7.6534e-01, 8.2294e-01,\n",
       "        3.5499e-01, 3.8070e-01, 4.1830e-01, 4.7575e-01, 6.6827e-01, 7.9144e-01,\n",
       "        3.1294e-01, 6.4080e-01, 3.2805e-01, 9.9845e-01, 1.9491e-01, 5.2387e-01,\n",
       "        6.9537e-01, 6.0259e-01, 2.2349e-03, 4.0231e-01, 2.6063e-01, 2.8860e-01,\n",
       "        5.6111e-01, 3.4430e-01, 2.3408e-01, 2.1252e-01, 8.1055e-01, 2.3760e-02,\n",
       "        7.4784e-01, 6.8554e-01, 6.5362e-01, 3.0798e-01, 8.9522e-01, 8.6773e-01,\n",
       "        7.0961e-01, 9.6072e-01, 2.6699e-01, 5.3064e-01, 5.9598e-01, 7.9922e-01,\n",
       "        4.6823e-01, 8.6427e-01, 8.6671e-01, 8.2572e-01, 9.5515e-01, 2.5390e-01,\n",
       "        5.1336e-01, 1.9697e-02, 7.1255e-01, 9.1416e-01, 9.8744e-01, 1.0205e-01,\n",
       "        8.6919e-01, 9.1073e-01, 5.7704e-01, 7.4205e-01, 9.4311e-01, 2.9994e-01,\n",
       "        5.6678e-02, 5.1772e-01, 7.3135e-01, 2.5007e-01, 5.3312e-01, 2.8895e-01,\n",
       "        9.7544e-01, 9.1187e-01, 3.3202e-01, 1.4936e-01, 6.8788e-01, 5.9110e-01,\n",
       "        5.9435e-01, 7.6444e-01, 5.3846e-01, 3.7588e-01, 5.8014e-01, 1.1285e-01,\n",
       "        1.1524e-01, 1.3072e-01, 6.6313e-01, 5.8065e-01, 9.0482e-01, 5.8276e-01,\n",
       "        7.6107e-01, 9.2551e-02, 1.0854e-02, 1.3225e-01, 3.1594e-01, 8.1822e-02,\n",
       "        6.0975e-01, 7.9995e-02, 9.5532e-01, 2.9076e-01, 3.9801e-01, 6.0546e-02,\n",
       "        9.5029e-01, 1.1655e-01, 7.0625e-01, 4.0885e-01, 1.8522e-01, 8.2081e-01,\n",
       "        1.9241e-01, 8.0624e-01, 1.1858e-01, 4.1228e-01, 8.5975e-01, 2.9592e-01,\n",
       "        6.4550e-01, 9.5549e-01, 2.9014e-01, 5.8314e-01, 7.4716e-01, 6.6775e-01,\n",
       "        1.3900e-01, 2.2551e-01, 6.3469e-01, 2.8566e-01, 1.5747e-01, 7.0600e-01,\n",
       "        3.8705e-01, 7.5783e-01, 7.7553e-01, 7.5610e-01, 3.2062e-01, 8.0767e-01,\n",
       "        3.2038e-02, 9.5487e-01, 2.2747e-01, 8.1950e-01, 6.8529e-01, 7.4688e-01,\n",
       "        5.4155e-01, 4.9093e-01, 5.6433e-01, 4.3693e-01, 9.0868e-01, 6.0556e-01,\n",
       "        2.1137e-01, 3.3881e-01, 4.5451e-01, 5.5697e-01, 1.4899e-01, 5.2179e-01,\n",
       "        5.4997e-01, 4.1752e-01, 3.6687e-01, 9.5894e-02, 2.6610e-01, 3.1822e-01,\n",
       "        1.1089e-02, 3.8107e-01, 7.7493e-01, 9.3304e-01, 9.5651e-01, 1.3359e-02,\n",
       "        6.7656e-01, 6.3034e-02, 2.0976e-01, 8.7615e-01, 3.7614e-01, 4.1037e-01,\n",
       "        4.0728e-02, 9.0182e-01, 1.8929e-01, 3.6367e-02, 2.0541e-02, 6.2665e-01,\n",
       "        6.1566e-01, 7.0508e-01, 5.5991e-01, 6.9928e-02, 7.5241e-01, 5.4370e-01,\n",
       "        9.0959e-01, 9.7845e-02, 3.8510e-02, 8.4799e-01, 6.7772e-01, 3.7037e-01,\n",
       "        3.9134e-01, 7.7930e-02, 6.6893e-01, 5.6977e-01, 5.6730e-01, 7.0712e-01,\n",
       "        2.3060e-01, 2.7725e-02, 6.8041e-01, 3.6587e-01, 2.1598e-02, 2.7724e-01,\n",
       "        3.7707e-01, 1.7778e-01, 4.7472e-01, 5.8070e-01, 8.6337e-01, 9.5856e-01,\n",
       "        2.5660e-01, 7.0375e-01, 4.5362e-01, 8.7169e-01, 6.5294e-01, 2.0823e-01,\n",
       "        4.1167e-01, 8.2299e-01, 4.3398e-01, 8.3975e-01, 1.4849e-01, 9.0156e-01,\n",
       "        8.7827e-01, 8.9838e-01, 9.1307e-01, 2.0841e-01, 7.6838e-01, 9.8273e-01,\n",
       "        4.1838e-03, 7.2739e-01, 8.7668e-01, 9.5500e-01, 5.2874e-01, 4.9778e-01,\n",
       "        6.1162e-01, 5.2321e-01, 9.6741e-01, 3.4106e-01, 2.6641e-01, 3.9058e-03,\n",
       "        7.8021e-01, 9.3997e-01, 2.2591e-01, 4.1220e-01, 9.9763e-01, 3.4649e-02,\n",
       "        2.4826e-01, 3.4626e-01, 1.3183e-01, 6.7864e-01, 5.3268e-01, 5.4414e-01,\n",
       "        5.2254e-01, 7.0862e-01, 7.2532e-01, 6.4233e-01, 5.6582e-01, 5.7155e-01,\n",
       "        8.2141e-01, 5.8613e-01, 4.6643e-01, 6.1479e-01, 2.2136e-01, 9.1106e-02,\n",
       "        9.9819e-01, 7.5566e-01, 5.0164e-01, 6.3699e-02, 2.9281e-01, 2.4465e-01,\n",
       "        2.0815e-01, 5.7640e-01, 3.0654e-01, 3.7782e-01, 5.8887e-01, 9.3036e-01,\n",
       "        8.8166e-01, 9.9094e-01, 4.0356e-01, 1.0085e-02, 2.9312e-02, 2.6334e-01,\n",
       "        3.4695e-01, 9.0108e-01, 2.9869e-01, 8.9717e-01, 4.5610e-01, 2.7193e-01,\n",
       "        5.3732e-01, 8.8009e-01, 1.9626e-01, 6.1966e-01, 8.9629e-01, 8.4794e-01,\n",
       "        8.5185e-01, 7.3411e-01, 6.5016e-03, 1.6398e-01, 9.8169e-02, 9.5097e-02,\n",
       "        3.9176e-01, 6.6296e-01, 9.4195e-01, 9.6129e-02, 4.4346e-01, 8.4319e-01,\n",
       "        7.9572e-01, 2.5716e-01, 9.2330e-01, 3.9252e-01, 5.0869e-01, 5.2504e-01,\n",
       "        3.9510e-01, 2.8489e-01, 6.5612e-01, 4.6690e-01, 1.4745e-01, 8.1914e-01,\n",
       "        2.6768e-01, 3.2143e-01, 3.8948e-01, 9.9957e-02, 7.4327e-01, 3.2646e-01,\n",
       "        7.4685e-01, 1.7632e-01, 9.3248e-01, 5.9296e-01, 9.6311e-01, 3.3649e-01,\n",
       "        6.6443e-01, 1.9259e-01, 8.9879e-01, 6.6482e-02, 6.8920e-01, 1.5520e-01,\n",
       "        7.5263e-01, 4.5097e-01, 3.5409e-01, 8.8107e-01, 1.6491e-01, 8.0787e-02,\n",
       "        4.3265e-01, 9.5679e-01, 3.6163e-01, 6.7333e-01, 8.1472e-01, 3.9363e-01,\n",
       "        4.7493e-01, 4.4763e-01, 6.9800e-01, 7.2464e-01, 1.7446e-01, 4.9908e-01,\n",
       "        6.0581e-01, 5.8505e-01, 5.9809e-01, 9.3663e-01, 6.6712e-01, 1.4758e-02,\n",
       "        9.5535e-01, 9.1973e-01, 5.0751e-01, 7.0149e-01, 9.2183e-01, 4.6195e-01,\n",
       "        8.5201e-01, 9.1469e-01, 7.9340e-01, 3.4302e-01, 9.2242e-01, 2.7712e-01,\n",
       "        1.8904e-01, 8.4782e-01, 5.4340e-01, 5.3469e-01, 8.6310e-01, 6.9784e-01,\n",
       "        8.1161e-02, 5.9773e-01, 7.6466e-01, 7.1115e-01, 6.8721e-01, 3.6234e-01,\n",
       "        3.6029e-01, 8.1073e-01, 1.4532e-01, 3.3148e-01, 9.2495e-01, 9.8177e-02,\n",
       "        4.0788e-02, 6.3493e-01, 6.7287e-01, 7.5003e-01, 7.9892e-01, 6.3461e-01,\n",
       "        2.2369e-01, 6.6261e-01, 3.4904e-01, 7.0117e-01, 5.6659e-01, 7.0526e-01,\n",
       "        7.4371e-01, 5.5828e-01, 5.7637e-02, 6.7167e-01, 5.4929e-01, 7.2176e-02,\n",
       "        9.5485e-01, 4.3236e-01, 9.4037e-01, 4.1418e-03, 4.1156e-03, 8.1557e-01,\n",
       "        7.5970e-01, 7.5558e-01, 8.1258e-01, 4.3402e-01, 8.2503e-01, 9.3027e-01,\n",
       "        6.1019e-01, 2.9670e-01, 9.4182e-01, 8.7022e-02, 8.0799e-01, 3.1821e-01,\n",
       "        9.0372e-01, 4.2680e-01, 5.4164e-02, 2.7165e-01, 1.5825e-01, 5.6219e-01,\n",
       "        8.4430e-01, 8.6112e-01, 3.3544e-01, 2.4265e-01, 2.2632e-01, 4.5245e-01,\n",
       "        2.0935e-02, 6.5742e-01, 2.0126e-01, 2.3233e-01, 2.6604e-01, 6.8127e-01,\n",
       "        2.8631e-02, 6.4944e-01, 1.8272e-02, 8.0182e-02, 6.0566e-01, 8.0711e-01,\n",
       "        6.1687e-01, 3.8385e-04, 1.3592e-01, 8.5783e-01, 8.9154e-01, 8.7983e-01,\n",
       "        7.6339e-01, 1.8495e-01, 9.2669e-01, 5.1686e-01, 7.7194e-01, 8.0367e-01,\n",
       "        6.3906e-02, 5.6201e-01, 3.1896e-02, 4.9283e-01, 6.1956e-01, 7.2847e-01,\n",
       "        2.0761e-01, 4.5938e-01, 9.7116e-01, 1.4670e-01, 4.7891e-01, 9.0672e-01,\n",
       "        4.7371e-01, 4.5160e-01, 3.6546e-01, 3.6101e-01, 1.4337e-01, 1.0151e-01,\n",
       "        7.6362e-01, 5.8412e-01, 5.3711e-01, 5.1298e-01, 2.7046e-01, 4.3859e-01,\n",
       "        2.7798e-01, 7.9442e-01, 9.4445e-01, 8.4656e-01, 8.8846e-01, 4.4385e-01,\n",
       "        1.2006e-01, 8.2858e-02, 4.6546e-01, 3.2646e-01, 9.2996e-01, 7.7028e-01,\n",
       "        6.1655e-01, 3.4664e-01, 2.7305e-01, 4.0401e-01, 7.8749e-01, 7.1313e-01,\n",
       "        7.3069e-01, 7.5079e-01, 4.7388e-01, 8.7162e-01, 9.5168e-01, 4.7987e-01,\n",
       "        8.7326e-01, 5.7272e-02, 5.6544e-01, 2.2848e-01, 9.9142e-01, 4.8942e-02,\n",
       "        2.6689e-01, 1.2739e-01, 8.7980e-01, 8.9612e-01, 6.1288e-02, 5.4961e-01,\n",
       "        5.0156e-01, 9.3792e-02, 2.2774e-01, 1.9182e-01, 5.6178e-01, 7.0513e-01,\n",
       "        9.4781e-01, 7.7058e-01, 6.9255e-01, 6.9954e-01, 4.2122e-01, 2.9607e-01,\n",
       "        1.0150e-01, 5.6896e-01, 9.6673e-01, 3.6043e-01, 8.7429e-01, 8.9169e-01,\n",
       "        7.6390e-01, 5.3926e-01, 4.5831e-02, 1.6495e-01, 5.8188e-01, 8.0447e-02,\n",
       "        9.9551e-01, 8.6751e-02, 8.0462e-01, 9.1549e-01, 5.9443e-01, 4.5110e-02])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
